---
title: See the Answer Faster
author: "Sam Castillo and Brian A. Fannin"
date: September XX, 2019
output: 
  revealjs::revealjs_presentation:
    center: no
    transition: slide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
    echo = FALSE
  , warning = FALSE
  , message = FALSE
  , collapse = TRUE
)

library(tidyverse)
library(gridExtra)
```

##

* Visual perception uses graphical space more efficiently than tabular data
* Statistical models are easier to refute visually
* The only useful graphics are ones that people look at
* Speed to production

# Spatial efficiency

## Many numbers - statistics

Statistics maps a set of many numbers into a set of fewer numbers.

```{r echo = TRUE}
set.seed(1234)
meanlog_actual <- log(10e3)
sdlog_actual <- 0.5

tbl_obs <- tibble(
  x = rlnorm(5e3, meanlog = meanlog_actual, sdlog = sdlog_actual)
)

tbl_obs$x %>% 
  summary()
```

```{r}
mean_sample <- tbl_obs$x %>% mean()
sd_sample <- tbl_obs$x %>% sd()
```

## Many numbers visually

```{r}
plt_base <- tbl_obs %>% 
  ggplot(aes(x))

plt_hist <- plt_base + 
  geom_histogram(
      aes(y = stat(density))
    , fill = 'grey'
    , color = 'black')

grid.arrange(
    nrow = 1
  , plt_hist
  , plt_base + geom_density(fill = 'grey')
)
```

## Many numbers visually

Looking at summary statistics is _always_ reduced information.

Looking at a visualization represents _all_ of the data, but forces our eyes to compute the statistics. 

Increased efficiency vs. decreased accuracy

## Seeing hypotheses

Many different sorts:

* Were the data generated by this form of distribution?
* Were these two samples generated by different processes?
* Is there a relationship between these two variables?

[list influenced by http://had.co.nz/stat645/graphical-inference.pdf]

## Sample data

```{r }
library(MASS)
fit_lnorm <- fitdistr(
    tbl_obs$x
  , 'log-normal'
)

est_meanlog <- fit_lnorm$estimate[1]
est_sd <- fit_lnorm$estimate[2]

tbl_obs <- tbl_obs %>% 
  mutate(
      percentile = percent_rank(x)
    , density_lnorm = dlnorm(x, est_meanlog, est_sd)
  )
```

```{r}
plt_hist
```

## Sample and hypothesis

```{r}
plt_hist +
  geom_line(data = tbl_obs, aes(x, density_lnorm), color = 'red')
```

## Hypothesis testing

* Kolmogorov-Smirnov
* Parameter significance
* $\chi^2$ test

Also:

Test against _other_ candidates, visually

## Could the data have come from somewhere else?

```{r}
shape <- (mean_sample / sd_sample) ^ 2
rate <- mean_sample / sd_sample ^ 2
# shape / rate
# (shape / rate^2) %>% sqrt()

library(MASS)
fit_weibull <- fitdistr(tbl_obs$x, 'weibull')
fit_gamma <- fitdistr(tbl_obs$x, 'gamma', lower = .01)

tbl_obs <- tbl_obs %>% 
  mutate(
      density_gamma_fitdistr = dgamma(x, fit_gamma$estimate[1], fit_gamma$estimate[2])
    , density_gamma_mom = dgamma(x, shape, rate)
    , density_weibull = dweibull(x, fit_weibull$estimate[1], fit_weibull$estimate[2])
  )
```

```{r }
tbl_obs %>% 
  dplyr::select(x, weibull = density_weibull, gamma = density_gamma_mom, lnorm = density_lnorm) %>% 
  tidyr::gather(distribution, density, -x) %>% 
  ggplot(aes(x)) + 
  geom_histogram(
      aes(y = stat(density))
    , fill = 'grey'
    , color = 'black') + 
  geom_line(aes(x, density, color = distribution))
```

## Exercise for the student

The same, but with:

* p-p or q-q plot
* Cumulative distribution function
* Isolate important areas of the distribution

## But now ...

Test the null itself!!

## Graphical inference

> Graphical inference helps us answer the question “Is what we see really there?”

- Hadley Wickham, Dianne Cook, Heike Hofmann, and Andreas Buja

http://had.co.nz/stat645/graphical-inference.pdf

H/T -> Xan Gregg @xangregg

## How it works

Visual test

1. Generate many (or 19) samples of the NULL
2. Add your actual data
3. Shuffle
4. Observe
5. Power may be increased by using more than one observer

## Can you spot the sample data?

```{r}
library(nullabor)
library(ggridges)

null_dist('x', 'gamma', params = list(shape = shape, rate = rate)) %>% 
  lineup(tbl_obs, pos = 13) %>% 
  mutate(sample = as.factor(.sample)) %>% 
  ggplot(aes(x, y = sample)) + 
  geom_density_ridges()
```

## How about now?

```{r }
null_dist('x', 'gamma', params = list(shape = shape, rate = rate)) %>% 
  lineup(tbl_obs, pos = 7) %>% 
  mutate(sample = as.factor(.sample)) %>%
  ggplot(aes(x)) + 
  geom_histogram() + 
  facet_wrap(~ sample) + 
  theme(axis.text.x = element_blank())
```

## Now?

```{r }
null_dist('x', 'gamma', params = list(shape = shape, rate = rate)) %>% 
  lineup(tbl_obs, pos = 17) %>% 
  mutate(sample = as.factor(.sample)) %>%
  ggplot(aes(sample, x)) + 
  geom_boxplot()
```

## A bit easier

```{r}
tbl_lineup_2 <- null_dist('x', 'weibull', params = list(shape = fit_weibull$estimate[1], scale = fit_weibull$estimate[2])) %>% 
  lineup(tbl_obs, pos = 5) %>% 
  mutate(sample = as.factor(.sample))

tbl_lineup_2 %>% 
  ggplot(aes(sample, x)) + 
  geom_boxplot()
```

## A bit harder

```{r}
tbl_lineup_3 <- null_dist(
    'x', 'log-normal', params = list(meanlog = meanlog_actual, sdlog = sdlog_actual)
  ) %>% 
  lineup(tbl_obs, pos = 14) %>% 
  mutate(sample = as.factor(.sample))

tbl_lineup_3 %>% 
  ggplot(aes(sample, x)) + 
  geom_boxplot()
```

## The statistical lineup

If can pick my data out of a lineup, I may reject the null hypothesis.

<!-- Humans **love** to infer relationships when they are not really there, especially visual ones. -->

## Seeing models

A "good" model is one which displays noise.  We are most interested in seeing something which _isn't_ there.

## Move along, nothing to see here

```{r}
data(anscombe)

tbl_anscombe <- anscombe %>% 
  tidyr::gather() %>% 
  tidyr::separate(key, c('var', 'segment'), sep = 1) %>% 
  group_by(var, segment) %>% 
  mutate(index = seq_len(n())) %>% 
  ungroup() %>% 
  tidyr::spread(var, value) %>% 
  mutate(
    segment = as.integer(segment)
  )
```

```{r}
fit_segment <- function(which_segment) {
  tbl_anscombe %>% 
    dplyr::filter(segment == which_segment) %>% 
    lm(formula = y ~ 1 + x)
}

tbl_fit <- tbl_anscombe %>% 
  group_by(segment) %>% 
  summarise(
    n = n()
  ) %>% 
  mutate(
    fit = map(segment, fit_segment)
  )

tbl_model <- map_dfr(tbl_fit$fit, broom::glance) %>% 
  mutate(segment = 1:4)
```

```{r}
tbl_model %>% 
  dplyr::select(segment, adj.r.squared, sigma) %>% 
  knitr::kable()
```

## Nothing to see?

```{r }
tbl_anscombe %>% 
  ggplot(aes(x, y)) + 
  geom_point() + 
  facet_wrap(~segment, scales = 'free') + 
  geom_smooth(method = 'lm', se = FALSE)
```

## Residuals

```{r}
tbl_residuals <- map_dfr(tbl_fit$fit, broom::augment) %>% 
  mutate(
    segment = rep(1:4, 11) %>% sort()
  ) %>% 
  rename(
    fitted = `.fitted`
    , residual = `.std.resid`
  )


tbl_residuals %>% 
  ggplot(aes(fitted, residual)) + 
  geom_point() + 
  facet_wrap(~ segment, scales = 'free') + 
  geom_hline(yintercept = 0, color = 'blue') + 
  geom_hline(yintercept = c(3, -3), color = 'red', linetype = 'dashed')
```

## Missing variables

Let's look at ozone data from `mlbench` package.

At first, we will only fit to `las_wind_speed`.

A simple model may tell us more than we think!

```{r}
library(mlbench)
data("Ozone")
names(Ozone) <- c(
    'month'
  , 'day_of_month'
  , 'day_of_week'
  , 'ozone'
  , 'pressure_vandenburg'
  , 'lax_wind_speed'
  , 'lax_humidity'
  , 'temp_sandburg'
  , 'temp_el_monte'
  , 'lax_inversion_height'
  , 'pressure_gradient'
  , 'lax_inversion_temp'
  , 'lax_visibility'
)

tbl_ozone <- Ozone %>% 
  filter(!is.na(ozone))
```

## Basic EDA

```{r }
tbl_ozone %>% 
  ggplot(aes(ozone)) + 
  geom_histogram(binwidth = 1)
```

## Our approach

* A very messy Poisson
* Fit a GLM with a subset of predictors
* Plot residuals against _all_ predictors 
* Look for pattern

## Missing variables

```{r}
fit_glm <- glm(
    formula = ozone ~ 1 + lax_wind_speed
  , data = tbl_ozone
  , family = poisson
)
```

```{r}
tbl_predict <- broom::augment(fit_glm)

tbl_predict <- tbl_predict %>% 
  dplyr::select(
    fitted = `.fitted`
    , residual = `.std.resid`
  ) %>% 
  cbind(tbl_ozone)

tbl_residual_compare <- tbl_predict %>% 
  tidyr::gather(predictor, value, -residual, -fitted) %>% 
  filter(predictor != 'ozone')
```

```{r}
tbl_residual_compare %>% 
  ggplot(aes(value, residual)) + 
  geom_point() + 
  facet_wrap(~ predictor, scales = 'free')
```

## Augment our model

Let's add lax inversion temperature!

## Missing variables redux

```{r}
fit_glm_all <- glm(
    formula = ozone ~ 1 + lax_inversion_temp
  , data = tbl_ozone
  , family = poisson
)

tbl_predict_all <- broom::augment(fit_glm_all, missing = NA)

tbl_predict_all <- tbl_predict_all %>% 
  dplyr::select(
      fitted = `.fitted`
    , residual = `.std.resid`
  ) %>% 
  cbind(filter(tbl_ozone, !is.na(lax_inversion_temp)))

tbl_residual_compare_all <- tbl_predict_all %>% 
  tidyr::gather(predictor, value, -residual, -fitted) %>% 
  filter(predictor != 'ozone')
```

```{r}
tbl_residual_compare_all %>% 
  ggplot(aes(value, residual)) + 
  geom_point() + 
  facet_wrap(~ predictor, scales = 'free')
```

## Thank you!

## Conclusions

* Visual perception uses graphical space more efficiently than tabular data
* Statistical models are easier to refute visually
* The only useful graphics are ones that people look at
* Speed to production

## References

* http://dicook.github.io/nullabor/index.html

## Where to find this

This presentation may be found at: http://pirategrunt.com/soa_symposium_2019/#/

Code to produce the examples and slides: https://github.com/PirateGrunt/soa_symposium_2019