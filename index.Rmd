---
title: See the Answer Faster
author: "Sam Castillo and Brian A. Fannin"
date: September XX, 2019
output: 
  revealjs::revealjs_presentation:
    center: no
    transition: slide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
    echo = FALSE
  , warning = FALSE
  , message = FALSE
  , collapse = TRUE
  , dev.args = list(type = "cairo") #creates better visuals than the default graphics device
)

library(tidyverse)
library(gridExtra)
library(Cairo)
library(vroom)
library(ggthemes)
library(png)
library(grid)
```

##

* Visual perception uses graphical space more efficiently than tabular data
* Statistical models are easier to refute visually
* The only useful graphics are ones that people look at
* Speed to production

# Spatial efficiency

## Many numbers - statistics

Statistics maps a set of many numbers into a set of fewer numbers.

```{r echo = TRUE}
set.seed(1234)
meanlog_actual <- log(10e3)
sdlog_actual <- 0.5

tbl_obs <- tibble(
  x = rlnorm(5e3, meanlog = meanlog_actual, sdlog = sdlog_actual)
)

tbl_obs$x %>% 
  summary()
```

```{r}
mean_sample <- tbl_obs$x %>% mean()
sd_sample <- tbl_obs$x %>% sd()
```

## Many numbers visually

```{r}
plt_base <- tbl_obs %>% 
  ggplot(aes(x))

plt_hist <- plt_base + 
  geom_histogram(
      aes(y = stat(density))
    , fill = 'grey'
    , color = 'black')

grid.arrange(
    nrow = 1
  , plt_hist
  , plt_base + geom_density(fill = 'grey')
)
```

## Many numbers visually

Looking at summary statistics is _always_ reduced information.

Looking at a visualization represents _all_ of the data, but forces our eyes to compute the statistics. 

Increased efficiency vs. decreased accuracy

## Seeing hypotheses

Many different sorts:

* Were the data generated by this form of distribution?
* Were these two samples generated by different processes?
* Is there a relationship between these two variables?

[list influenced by http://had.co.nz/stat645/graphical-inference.pdf]

## Sample data

```{r }
library(MASS)
fit_lnorm <- fitdistr(
    tbl_obs$x
  , 'log-normal'
)

est_meanlog <- fit_lnorm$estimate[1]
est_sd <- fit_lnorm$estimate[2]

tbl_obs <- tbl_obs %>% 
  mutate(
      percentile = percent_rank(x)
    , density_lnorm = dlnorm(x, est_meanlog, est_sd)
  )
```

```{r}
plt_hist
```

## Sample and hypothesis

```{r}
plt_hist +
  geom_line(data = tbl_obs, aes(x, density_lnorm), color = 'red')
```

## Hypothesis testing

* Kolmogorov-Smirnov
* Parameter significance
* $\chi^2$ test

Also:

Test against _other_ candidates, visually

## Could the data have come from somewhere else?

```{r}
shape <- (mean_sample / sd_sample) ^ 2
rate <- mean_sample / sd_sample ^ 2
# shape / rate
# (shape / rate^2) %>% sqrt()

library(MASS)
fit_weibull <- fitdistr(tbl_obs$x, 'weibull')
fit_gamma <- fitdistr(tbl_obs$x, 'gamma', lower = .01)

tbl_obs <- tbl_obs %>% 
  mutate(
      density_gamma_fitdistr = dgamma(x, fit_gamma$estimate[1], fit_gamma$estimate[2])
    , density_gamma_mom = dgamma(x, shape, rate)
    , density_weibull = dweibull(x, fit_weibull$estimate[1], fit_weibull$estimate[2])
  )
```

```{r }
tbl_obs %>% 
  dplyr::select(x, weibull = density_weibull, gamma = density_gamma_mom, lnorm = density_lnorm) %>% 
  tidyr::gather(distribution, density, -x) %>% 
  ggplot(aes(x)) + 
  geom_histogram(
      aes(y = stat(density))
    , fill = 'grey'
    , color = 'black') + 
  geom_line(aes(x, density, color = distribution))
```

## Exercise for the student

The same, but with:

* p-p or q-q plot
* Cumulative distribution function
* Isolate important areas of the distribution

## But now ...

Test the null itself!!

## Graphical inference

> Graphical inference helps us answer the question “Is what we see really there?”

- Hadley Wickham, Dianne Cook, Heike Hofmann, and Andreas Buja

http://had.co.nz/stat645/graphical-inference.pdf

H/T -> Xan Gregg @xangregg

## How it works

Visual test

1. Generate many (or 19) samples of the NULL
2. Add your actual data
3. Shuffle
4. Observe
5. Power may be increased by using more than one observer

## Can you spot the sample data?

```{r}
library(nullabor)
library(ggridges)

null_dist('x', 'gamma', params = list(shape = shape, rate = rate)) %>% 
  lineup(tbl_obs, pos = 13) %>% 
  mutate(sample = as.factor(.sample)) %>% 
  ggplot(aes(x, y = sample)) + 
  geom_density_ridges()
```

## How about now?

```{r }
null_dist('x', 'gamma', params = list(shape = shape, rate = rate)) %>% 
  lineup(tbl_obs, pos = 7) %>% 
  mutate(sample = as.factor(.sample)) %>%
  ggplot(aes(x)) + 
  geom_histogram() + 
  facet_wrap(~ sample) + 
  theme(axis.text.x = element_blank())
```

## Now?

```{r }
null_dist('x', 'gamma', params = list(shape = shape, rate = rate)) %>% 
  lineup(tbl_obs, pos = 17) %>% 
  mutate(sample = as.factor(.sample)) %>%
  ggplot(aes(sample, x)) + 
  geom_boxplot()
```

## A bit easier

```{r}
tbl_lineup_2 <- null_dist('x', 'weibull', params = list(shape = fit_weibull$estimate[1], scale = fit_weibull$estimate[2])) %>% 
  lineup(tbl_obs, pos = 5) %>% 
  mutate(sample = as.factor(.sample))

tbl_lineup_2 %>% 
  ggplot(aes(sample, x)) + 
  geom_boxplot()
```

## A bit harder

```{r}
tbl_lineup_3 <- null_dist(
    'x', 'log-normal', params = list(meanlog = meanlog_actual, sdlog = sdlog_actual)
  ) %>% 
  lineup(tbl_obs, pos = 14) %>% 
  mutate(sample = as.factor(.sample))

tbl_lineup_3 %>% 
  ggplot(aes(sample, x)) + 
  geom_boxplot()
```

## The statistical lineup

If can pick my data out of a lineup, I may reject the null hypothesis.

<!-- Humans **love** to infer relationships when they are not really there, especially visual ones. -->

## Seeing models

A "good" model is one which displays noise.  We are most interested in seeing something which _isn't_ there.

## Move along, nothing to see here

```{r}
data(anscombe)

tbl_anscombe <- anscombe %>% 
  tidyr::gather() %>% 
  tidyr::separate(key, c('var', 'segment'), sep = 1) %>% 
  group_by(var, segment) %>% 
  mutate(index = seq_len(n())) %>% 
  ungroup() %>% 
  tidyr::spread(var, value) %>% 
  mutate(
    segment = as.integer(segment)
  )
```

```{r}
fit_segment <- function(which_segment) {
  tbl_anscombe %>% 
    dplyr::filter(segment == which_segment) %>% 
    lm(formula = y ~ 1 + x)
}

tbl_fit <- tbl_anscombe %>% 
  group_by(segment) %>% 
  summarise(
    n = n()
  ) %>% 
  mutate(
    fit = map(segment, fit_segment)
  )

tbl_model <- map_dfr(tbl_fit$fit, broom::glance) %>% 
  mutate(segment = 1:4)
```

```{r}
tbl_model %>% 
  dplyr::select(segment, adj.r.squared, sigma) %>% 
  knitr::kable()
```

## Nothing to see?

```{r }
tbl_anscombe %>% 
  ggplot(aes(x, y)) + 
  geom_point() + 
  facet_wrap(~segment, scales = 'free') + 
  geom_smooth(method = 'lm', se = FALSE)
```

## Residuals

```{r}
tbl_residuals <- map_dfr(tbl_fit$fit, broom::augment) %>% 
  mutate(
    segment = rep(1:4, 11) %>% sort()
  ) %>% 
  rename(
    fitted = `.fitted`
    , residual = `.std.resid`
  )


tbl_residuals %>% 
  ggplot(aes(fitted, residual)) + 
  geom_point() + 
  facet_wrap(~ segment, scales = 'free') + 
  geom_hline(yintercept = 0, color = 'blue') + 
  geom_hline(yintercept = c(3, -3), color = 'red', linetype = 'dashed')
```

## Missing variables

Let's look at ozone data from `mlbench` package.

At first, we will only fit to `las_wind_speed`.

A simple model may tell us more than we think!

```{r}
library(mlbench)
data("Ozone")
names(Ozone) <- c(
    'month'
  , 'day_of_month'
  , 'day_of_week'
  , 'ozone'
  , 'pressure_vandenburg'
  , 'lax_wind_speed'
  , 'lax_humidity'
  , 'temp_sandburg'
  , 'temp_el_monte'
  , 'lax_inversion_height'
  , 'pressure_gradient'
  , 'lax_inversion_temp'
  , 'lax_visibility'
)

tbl_ozone <- Ozone %>% 
  filter(!is.na(ozone))
```

## Basic EDA

```{r }
tbl_ozone %>% 
  ggplot(aes(ozone)) + 
  geom_histogram(binwidth = 1)
```

## Our approach

* A very messy Poisson
* Fit a GLM with a subset of predictors
* Plot residuals against _all_ predictors 
* Look for pattern

## Missing variables

```{r}
fit_glm <- glm(
    formula = ozone ~ 1 + lax_wind_speed
  , data = tbl_ozone
  , family = poisson
)
```

```{r}
tbl_predict <- broom::augment(fit_glm)

tbl_predict <- tbl_predict %>% 
  dplyr::select(
    fitted = `.fitted`
    , residual = `.std.resid`
  ) %>% 
  cbind(tbl_ozone)

tbl_residual_compare <- tbl_predict %>% 
  tidyr::gather(predictor, value, -residual, -fitted) %>% 
  filter(predictor != 'ozone')
```

```{r}
tbl_residual_compare %>% 
  ggplot(aes(value, residual)) + 
  geom_point() + 
  facet_wrap(~ predictor, scales = 'free')
```

## Augment our model

Let's add lax inversion temperature!

## Missing variables redux

```{r}
fit_glm_all <- glm(
    formula = ozone ~ 1 + lax_inversion_temp
  , data = tbl_ozone
  , family = poisson
)

tbl_predict_all <- broom::augment(fit_glm_all, missing = NA)

tbl_predict_all <- tbl_predict_all %>% 
  dplyr::select(
      fitted = `.fitted`
    , residual = `.std.resid`
  ) %>% 
  cbind(filter(tbl_ozone, !is.na(lax_inversion_temp)))

tbl_residual_compare_all <- tbl_predict_all %>% 
  tidyr::gather(predictor, value, -residual, -fitted) %>% 
  filter(predictor != 'ozone')
```

```{r}
tbl_residual_compare_all %>% 
  ggplot(aes(value, residual)) + 
  geom_point() + 
  facet_wrap(~ predictor, scales = 'free')
```

## Thank you!

## Conclusions

* Visual perception uses graphical space more efficiently than tabular data
* Statistical models are easier to refute visually
* The only useful graphics are ones that people look at
* Speed to production

## References

* http://dicook.github.io/nullabor/index.html

# Productivity

1. Branding your data visualizations
2. Producing graphs quickly
3. 

## Data visualization communicates your brand

* Your customers and clients judge your product based on appearance
* When writing a resume, professionalism matters


## Default graphics

```{r}
iris %>% 
  ggplot(aes(Sepal.Width, Sepal.Length, color = Species)) + 
  geom_point()
```



## Professional graphics

```{r}
source("theme_soa.R")

img <- readPNG("images/soa_logo.png")
logo <- rasterGrob(img, interpolate = T)

qplot(1:10, 1:10, geom = "blank") + 
  annotation_custom(logo) 


gg <- iris %>% 
  ggplot(aes(Sepal.Width, Sepal.Length, color = Species)) + 
  geom_point(size = 2) + 
  theme_classic() + 
  labs("") + 
  theme(legend.position = "top") + 
  xlab("X Label") + 
  ylab("Y Label") +
  theme_soa() + 
  ggtitle("FivethirtyEight theme") + 
  labs( subtitle = "Based on fivethirtyeight's theme \nfrom the 'ggthemes' package",
        caption = "Copyright 2019 YourBrandName \nUsed without Permission") + 
   annotation_custom(logo, ymin = 8.5, ymax = 9, xmin = 4, xmax = 4.5) 

gt <- ggplot_gtable(ggplot_build(gg))
gt$layout$clip[gt$layout$name=="panel"] <- "off"
grid.draw(gt)

```

## What should actuaries look for?

* Readability
* Honesty - it should be representative of the underlying data
* Reference ASOP

## Bad - Difficult to read

* What are the units?
* What are the X and Y axis?
* What is the data source?


```{r fig.height=4}
readmissions <- read_csv("hospital_readmission_rates.csv", na = "Not Available")

readmissions %>% 
  ggplot(aes(`Number of Readmissions`)) + 
  geom_histogram() +
  ggtitle("Hospital Readmissions")
```



## Good example - easy to read

* There are just over 2,000 hospitals with between 30 and 50 readmissions
* There are 4,000 hospitals with between 10 and 30 

```{r fig.height=4}
readmissions %>% 
  ggplot(aes(`Number of Readmissions`)) + 
  geom_histogram(binwidth = 20, color = "Light Grey", size = 1.2) + 
  xlim(0, 300) + 
  theme_soa() + 
  ggtitle("Distribution of Hospital Readmissions") + 
  xlab("Number of Readmissions") + 
  ylab("Number of Hospitals") + 
  labs( subtitle = "Based on Five Thirty Eight's Theme \nfrom the 'ggthemes' package",
        caption = "Copyright 2019 YourBrandName \nData Source: HealthData.gov") + 
   annotation_custom(logo, ymin = 8.5, ymax = 9, xmin = 4, xmax = 4.5) + 
  scale_x_continuous(breaks = seq(10, 300, 20),minor_breaks = seq(0, 300, 10), limits = c(0, 300))
```

## Bad example - Excel mixed type graph

* Which axis is the Actual and which is the Predicted?  
* The blue bars take up more visual space than the lines, but both units are equally important
* The lines do not even make sense because there is no continuous scale (States are not related to each other)

![*Excel Mixed Type Graph*](images/excel_pivot_1.PNG)

## Good example - box plot of AvE ratio

```{r message = F, warning = F}
readmissions %>% 
  filter(State %in% c("IL", "MA", "NC", "NY", "PA")) %>% 
  mutate(ave = `Expected Readmission Rate`/`Predicted Readmission Rate`) %>% 
  ggplot(aes(State, ave, fill = State)) + 
  geom_boxplot(outlier.alpha = 0.2, alpha = 0.7) + 
  coord_flip() + 
  theme_soa() + 
  ggtitle("Actual vs Expected Readmission Ratio") + 
  ylab("Actual/Predicted") +
  labs( subtitle = "Based on Five Thirty Eight's Theme \nfrom the 'ggthemes' package",
        caption = "Copyright 2019 YourBrandName \nData Source: HealthData.gov") + 
  annotation_custom(logo, ymin = 8.5, ymax = 9, xmin = 4, xmax = 4.5) 

```


## How to create graphics like this quickly

Creating a graph is an assembly line

1.  Get data in the right format
2.  Explore an idea - Discovery is a spontaneous process
3.  Plot a graph
4.  Put it in front of people



## Where to find this

This presentation may be found at: http://pirategrunt.com/soa_symposium_2019/#/

Code to produce the examples and slides: https://github.com/PirateGrunt/soa_symposium_2019